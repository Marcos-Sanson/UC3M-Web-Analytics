{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marcos-Sanson/UC3M-Web-Analytics/blob/main/Beautiful_Soup_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afwfMTuQT2O0"
      },
      "source": [
        "# **WEB ANALYTICS – Data Science and Engineering Degree**  \n",
        "## *(1st Semester, 4th-Year-Level Course)*  \n",
        "\n",
        "### **Web Scraping with BeautifulSoup**  \n",
        "\n",
        "This lab was part of my **Web Analytics** course at **Universidad Carlos III de Madrid (UC3M)**, where I studied abroad from **September 2024 to December 2024** as part of my Computer Science degree. This specific lab focused on **web scraping techniques** using **Python, Requests, and BeautifulSoup** to extract structured data from websites. The lab introduced **HTML parsing, DOM traversal, and automated data collection**, providing hands-on experience in gathering information from public web pages.  \n",
        "\n",
        "Working in a group of three students, we developed a **web scraper** to extract information from various sources to apply **best practices in web crawling, data extraction, and API request handling**.  \n",
        "\n",
        "### **Web Scraping and Data Extraction**  \n",
        "\n",
        "We implemented a series of milestones that covered **real-world web scraping scenarios**, including:  \n",
        "- Extracting **university program details** from the **UC3M website**.  \n",
        "- Navigating **HTML elements and attributes** using **BeautifulSoup**.  \n",
        "- Scraping **automobile listings** to build a **price monitoring system**.  \n",
        "- Identifying **robots.txt restrictions** to respect website policies.  \n",
        "\n",
        "### **Milestones**  \n",
        "\n",
        "#### **Milestone 1: Extracting University Program Data**  \n",
        "We accessed the **Bachelor in Data Science and Engineering program** page at UC3M and extracted key details:  \n",
        "- Located and printed the **\"Quality\"** section from the page.  \n",
        "- Retrieved and displayed **available student places per campus**.  \n",
        "\n",
        "#### **Milestone 2: Extracting Course-Specific Information**  \n",
        "We followed an internal link to the **Web Analytics course page** and used BeautifulSoup to extract:  \n",
        "- The **URL linking to the Web Analytics course**.  \n",
        "- The **Objectives section**, detailing the course's learning outcomes in **data visualization, web crawling, and machine learning applications**.  \n",
        "\n",
        "#### **Milestone 3: Scraping Automobile Listings for Price Monitoring**  \n",
        "We developed an initial **price monitoring system** for **second-hand SEAT vehicles in Madrid**:  \n",
        "- Verified that **robots.txt** did not restrict scraping for this data.  \n",
        "- Scraped the **Yamovil website**, extracting:  \n",
        "  - **Car make, model, and version**.  \n",
        "  - **Listed prices for 30 available SEAT vehicles**.  \n",
        "\n",
        "This milestone demonstrated the **practical application of web scraping for market research** to enable **automated data collection for price tracking**.  \n",
        "\n",
        "### **Outcome**  \n",
        "Through this lab, we gained experience in **web scraping fundamentals**, including **HTML parsing, data extraction, and web automation**. We developed **Python-based web scrapers**, applied **ethical scraping techniques**, and **navigated real-world website structures** to extract valuable information efficiently.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NeV05Oml2dF"
      },
      "source": [
        "# 0. Lab Preparation\n",
        "\n",
        "1.  Study and have clear the concepts explained in the theoretical class and the introductory lab.\n",
        "\n",
        "2.   Gain experience with the use of the [Requests](https://docs.python-requests.org/en/master/) and [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). The exercises of this lab will be mainly based on the utilization of functions offered by these libraries.\n",
        "\n",
        "3. It is assumed students have experience in using Python notebooks. Either a local installation (e.g., local python installation + Jupyter) or a cloud-based solution (e.g., Google Colab). *We recommend the second option*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7WfODWPm67o"
      },
      "source": [
        "# 1. Lab Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMRIv1eekgK0"
      },
      "source": [
        "* In this lab, we will implement a web scraper using the parsing library [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). One of the tools explained in the theoretical class.\n",
        "\n",
        "* The lab will be done in groups of 3 people.\n",
        "\n",
        "* The lab defines a set of milestones the students must complete. Upon completing every milestone, students should call the professor, who will check the correctness of the solution (*If the professor is busy, do not wait for them, move to the next milestone*).\n",
        "\n",
        "* **The final mark will be computed as a function of the number of milestones successfully completed.**\n",
        "\n",
        "* **Each group should also share their lab notebook with the professor upon the finalization of the lab.**\n",
        "\n",
        "* In this lab we will use the [Requests](https://docs.python-requests.org/en/master/) and [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) libraries for the creation of a web scraper, to extract information from the web. As indicated in the *Lab Preparation* section above, it is expected that students have gained experience in the use of the libraries before starting the first session of the lab.\n",
        "\n",
        "- It is recommended to use [Google Colab](https://colab.research.google.com/) to produce the Python notebook with the solution of the lab. Of course, if any student prefers using its local programming environment (e.g., jupyter) and python installation, they are welcome to do so."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_W-5JKjoiDb"
      },
      "source": [
        "# MILESTONE 1\n",
        "\n",
        "a) Access to the website [BACHELOR IN DATA SCIENCE AND ENGINEERING\n",
        "](https://www.uc3m.es/bachelor-degree/data-science)\n",
        "\n",
        "b) Create the _BeautifulSoup_ object.\n",
        "\n",
        "c) Find the element tag with `id=\"quality\"` and print the result.\n",
        "\n",
        "d) Find the `Places offered:` inside QUALITY and print the result.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et_kjc37yycj"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJbMg_xfy9D8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e4076a-ee0b-4f75-a006-37a4ef1275f5"
      },
      "source": [
        "web_url = \"https://www.uc3m.es/bachelor-degree/data-science#program\"\n",
        "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36'\n",
        "page_0 = requests.get(web_url)\n",
        "\n",
        "soup_0 = BeautifulSoup(page_0.content, \"html.parser\")\n",
        "\n",
        "element_tag = soup_0.find_all(id='quality')\n",
        "print(element_tag)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<div class=\"marcoParrafo\" id=\"quality\">\n",
            "<h2>Quality</h2>\n",
            "</div>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk1O9wzKz1lC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e99d581-0cec-4c18-93a4-f1d0c695cc6f"
      },
      "source": [
        "places_offered = soup_0.find(\"p\", string=\"Places offered:\").find_next().text\n",
        "\n",
        "print(places_offered)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Leganes Campus: 50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfJJ5jXioaeA"
      },
      "source": [
        "# MILESTONE 2\n",
        "\n",
        "a) Obtain the link to Web Analytics course (see inside Program) by finding the corresponding href with _BeautifulSoup_.\n",
        "\n",
        "b) Access to this URL and create a new _BeautifulSoup_ object.\n",
        "\n",
        "c) Print the text inside the Objectives section.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSp3Zrq2b_-M"
      },
      "source": [
        "web_analytics_url = \"https://aplicaciones.uc3m.es/cpa/generaFicha?&est=350&plan=392&asig=16507&idioma=2\"\n",
        "\n",
        "page_1 = requests.get(web_analytics_url)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8UG5eP4b_6V"
      },
      "source": [
        "soup_1 = BeautifulSoup(page_1.content, \"html.parser\")\n",
        "\n",
        "content = soup_1.find_all(class_='tarea')[1].text\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNMexjQxb_11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d3a369-3fdf-4aa6-dec1-92349bc23a21"
      },
      "source": [
        "print(content)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Students should be able to demonstrate they have acquired and understood the knowledge associated to an area that starts from high school education and reach a level that although it is based on text books, it also includes aspects that include concepts coming from up-to-date knowledge in the referread area.\n",
            "2. Students should be able to apply the acquired knowledge to their job in a professional way and should incorporate the required competences that can be shown through solid arguments and the resolution of problems within their area of study.\n",
            "3. Ability to design solutions based on automatic knowledge within applications applied to specific domains such as: recommendation systems, natural language processing, the WEB or online social networks.\n",
            "4. Ability to develop web and mobile applications and crawlers to collect data using  them.\n",
            "5. Ability to develop data visualization tools to communicate the results derived from data analysis.\n",
            "6. Adequate knowledge and skills to analyze and synthesize basic problems related to engineering and data science, solve them and communicate them efficiently\n",
            "7. Ability to solve problems with initiative, decision making, creativity, and to communicate and transmit knowledge, skills and abilities, understanding the ethical, social and professional responsibility of the data processing activity. Leadership capacity, innovation and entrepreneurial spirit\n",
            "8. Ability to communicate knowledge orally and in writing to both specialised and non-specialised audiences\n",
            "9. Students should have acquired advanced knowledge and demonstrated an understanding of the theoretical and practical aspects and working\n",
            "methodology in the field of data science and engineering with a depth that reaches the forefront of knowledge\n",
            "10. Be capable of applying their knowledge and problem-solving skills, through arguments or procedures developed and sustained by themselves, in\n",
            "complex or professional and specialized work settings that require the use of creative and innovative ideas.\n",
            "11. Have the ability to collect and interpret data and information on which to base their conclusions including, where appropriate and pertinent, reflection on issues of a social, scientific or ethical nature within their field of study\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvWXdKNY23Yw"
      },
      "source": [
        "# MILESTONE 3\n",
        "\n",
        "Now let's build the first steps for a price monitoring website. For that, we are going to use yamovil.com to obtain car prices. Specifically, we want to find SEAT cars in Madrid and the price of each of them.\n",
        "\n",
        "Follow these steps:\n",
        "\n",
        "a) Check https://www.yamovil.es/robots.txt and see if the site can be crawled or not for our specific search. Explain.\n",
        "\n",
        "b) If yes, use this [URL](https://www.yamovil.es/coches-segunda-mano/seat-ocasion-en-madrid) which already includes the indicated search (SEAT Cars Madrid Second Hand), scrape the HTML using _BeautifulSoup_, and print the **mark**, **model**, **version** and **price** of each available car.\n",
        "\n",
        "**HINT:** The resulting list should have 30 cars (which are the ones that appear in the first page)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***a) Yes, the site can be crawled, because on the robots.txt page it only excludes the following:***\n",
        "\n",
        "User-agent: *\n",
        "*   Disallow: /admin/\n",
        "*   Disallow: /feed/\n",
        "*   Disallow: /goal/\n",
        "*   Disallow: /sobre-coches-y-concesionarios/category/\n",
        "*   Disallow: /sobre-coches-y-concesionarios/articulos/\n",
        "*   Disallow: /sobre-coches-y-concesionarios/author/\n",
        "\n",
        "Which doesn't include our specific search for SEAT Cars Madrid Second Hand. It would disallow us on those other pages, however."
      ],
      "metadata": {
        "id": "mf-M4dHSzJ9J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvC5-azycBkh"
      },
      "source": [
        "yamovil_url = \"https://www.yamovil.es/coches-segunda-mano/seat-ocasion-en-madrid\"\n",
        "page_2 = requests.get(yamovil_url)\n",
        "\n",
        "soup_2 = BeautifulSoup(page_2.content, \"html.parser\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyKkKXzwcBht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8151a2d-bf82-4935-cb36-e0f7b33a28f9"
      },
      "source": [
        "list = soup_2.find_all(class_='vehicle-list__item')\n",
        "for i in list:\n",
        "  print(i.find(class_='make').text)\n",
        "  print(i.find(class_='model').text)\n",
        "  print(i.find(class_='version').text)\n",
        "  print(i.find(class_='price').text)\n",
        "\n",
        "  print(len(list))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seat\n",
            "Arona\n",
            "1.0 TSI Style Plus 81 kW (110 CV)\n",
            "15.750€\n",
            "30\n",
            "Seat\n",
            "Ateca\n",
            "1.4 EcoTSI SANDS Xcellence 4Drive DSG 110 kW (150 CV)\n",
            "19.650€\n",
            "30\n",
            "Seat\n",
            "Arona\n",
            "1.0 TSI Ecomotive SANDS Style Edition 70 kW (95 CV)\n",
            "14.950€\n",
            "30\n",
            "Seat\n",
            "Arona\n",
            "1.0 TSI FR Go2 81 kW (110 CV)\n",
            "15.980€\n",
            "30\n",
            "Seat\n",
            "Mii\n",
            "1.0 Cosmopolitan 55 kW (75 CV)\n",
            "7.750€\n",
            "30\n",
            "Seat\n",
            "Arona\n",
            "1.0 TSI Ecomotive Style Edition 85 kW (115 CV)\n",
            "13.950€\n",
            "30\n",
            "Seat\n",
            "Leon ST\n",
            "1.0 TSI SANDS Style 85 kW (115 CV)\n",
            "13.450€\n",
            "30\n",
            "Seat\n",
            "Ateca\n",
            "1.5 TSI SANDS Style XL DSG 110 kW (150 CV)\n",
            "23.490€\n",
            "30\n",
            "Seat\n",
            "Ibiza\n",
            "1.6 TDI Reference 66 kW (90 CV)\n",
            "8.950€\n",
            "30\n",
            "Seat\n",
            "Ibiza\n",
            "1.4 TDI Reference 51 kW (70 CV)\n",
            "6.750€\n",
            "30\n",
            "Seat\n",
            "Tarraco\n",
            "1.5 TSI SANDS Style Edition 110 kW (150 CV)\n",
            "32.450€\n",
            "30\n",
            "Seat\n",
            "Ateca\n",
            "1.5 TSI SANDS Style Go M 110 kW (150 CV)\n",
            "20.480€\n",
            "30\n",
            "Seat\n",
            "Ateca\n",
            "1.5 TSI SANDS FR XL DSG 110 kW (150 CV)\n",
            "27.480€\n",
            "30\n",
            "Seat\n",
            "Arona\n",
            "1.0 TSI FR XM DSG 81 kW (110 CV)\n",
            "19.350€\n",
            "30\n",
            "Seat\n",
            "Leon ST\n",
            "2.0 TDI SANDS FR Edition DSG-7  110 kW (150 CV)\n",
            "19.450€\n",
            "30\n",
            "Seat\n",
            "León\n",
            "1.5 TSI SANDS FR Edition 96 kW (130 CV)\n",
            "16.750€\n",
            "30\n",
            "Seat\n",
            "Leon ST\n",
            "1.5 EcoTSI SANDS FR DSG 110 kW (150 CV)\n",
            "17.450€\n",
            "30\n",
            "Seat\n",
            "Leon ST\n",
            "1.5 EcoTSI SANDS FR DSG 110 kW (150 CV)\n",
            "17.480€\n",
            "30\n",
            "Seat\n",
            "León\n",
            "1.5 TSI SANDS Xcellence Go M 96 kW (130 CV)\n",
            "18.450€\n",
            "30\n",
            "Seat\n",
            "Mii\n",
            "1.0 Style 55 kW (75 CV)\n",
            "6.990€\n",
            "30\n",
            "Seat\n",
            "Ibiza\n",
            "1.0 TSI Xcellence Plus DSG 81 kW (110 CV)\n",
            "15.950€\n",
            "30\n",
            "Seat\n",
            "Ibiza\n",
            "1.0 EcoTSI SANDS FR 85 kW (115 CV)\n",
            "13.450€\n",
            "30\n",
            "Seat\n",
            "Tarraco\n",
            "2.0 TDI SANDS Xcellence GO DSG 110 kW (150 CV)\n",
            "27.480€\n",
            "30\n",
            "Seat\n",
            "Ateca\n",
            "2.0 TDI SANDS Style Plus Nav 4Drive 110 kW (150 CV)\n",
            "19.950€\n",
            "30\n",
            "Seat\n",
            "Leon ST\n",
            "1.5 TSI SANDS Xcellence Go L 96 kW (130 CV)\n",
            "18.450€\n",
            "30\n",
            "Seat\n",
            "Ibiza\n",
            "1.2 12v Reference ITech 30 Aniversario 51 kW (70 CV)\n",
            "8.950€\n",
            "30\n",
            "Seat\n",
            "Ateca\n",
            "1.5 TSI SANDS X-Perience Go 110 kW (150 CV)\n",
            "21.390€\n",
            "30\n",
            "Seat\n",
            "Ateca\n",
            "1.5 TSI SANDS Xcellence Edition 110 kW (150 CV)\n",
            "18.950€\n",
            "30\n",
            "Seat\n",
            "Ateca\n",
            "1.6 TDI SANDS Ecomotive Xcellence Plus 85 kW (115 CV)\n",
            "18.950€\n",
            "30\n",
            "Seat\n",
            "Arona\n",
            "1.0 TSI SANDS FR XM Edition 81 kW (110 CV)\n",
            "17.950€\n",
            "30\n"
          ]
        }
      ]
    }
  ]
}